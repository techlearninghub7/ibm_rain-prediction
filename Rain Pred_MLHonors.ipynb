{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rain Prediction in Australia Using Classification Algorithms\n",
    "#### This project was done as a part of Honors Content in Machine Learning with Python Couse in the IBM Data Science Professional Certificate.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Table of Contents</h2>\n",
    "\n",
    "* Basic Process\n",
    "* Describing Data\n",
    "* Importing Data<br>\n",
    "* Data Preprocessing<br>\n",
    "* Transforming Categorical Variables<br>\n",
    "* Train and Test Data Splitting<br>\n",
    "* Training Linear Regression, KNN, Decision Tree, Logistic Regression, and SVM models<br>\n",
    "* Comparing their accuracy scores\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview of the process\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to use the classification algorithms to create a model based on our training data and evaluate our testing data using various evaluation metrics.\n",
    "\n",
    "We will use these algorithms:\n",
    "\n",
    "1.  Linear Regression\n",
    "2.  KNN\n",
    "3.  Decision Trees\n",
    "4.  Logistic Regression\n",
    "5.  SVM\n",
    "\n",
    "We will evaluate our models using:\n",
    "\n",
    "1.  Accuracy Score\n",
    "2.  Jaccard Index\n",
    "3.  F1-Score\n",
    "4.  LogLoss\n",
    "5.  Mean Absolute Error\n",
    "6.  Mean Squared Error\n",
    "7.  R2-Score\n",
    "\n",
    "Finally, we will use models to generate the report displaying the accuracy scores.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Gathering\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The original source of the data is Australian Government's Bureau of Meteorology and the latest data can be gathered from [http://www.bom.gov.au/climate/dwo/](http://www.bom.gov.au/climate/dwo/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkML0101ENSkillsNetwork20718538-2022-01-01).\n",
    "\n",
    "The dataset to be used has extra columns like 'RainToday' and our target is 'RainTomorrow', which was gathered from the Rattle at [https://bitbucket.org/kayontoga/rattle/src/master/data/weatherAUS.RData](https://bitbucket.org/kayontoga/rattle/src/master/data/weatherAUS.RData?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkML0101ENSkillsNetwork20718538-2022-01-01)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset contains observations of weather metrics for each day from 2008 to 2017. The **weatherAUS.csv** dataset includes the following fields:\n",
    "\n",
    "| Field         | Description                                           | Unit            | Type   |\n",
    "| ------------- | ----------------------------------------------------- | --------------- | ------ |\n",
    "| Date          | Date of the Observation in YYYY-MM-DD                 | Date            | object |\n",
    "| Location      | Location of the Observation                           | Location        | object |\n",
    "| MinTemp       | Minimum temperature                                   | Celsius         | float  |\n",
    "| MaxTemp       | Maximum temperature                                   | Celsius         | float  |\n",
    "| Rainfall      | Amount of rainfall                                    | Millimeters     | float  |\n",
    "| Evaporation   | Amount of evaporation                                 | Millimeters     | float  |\n",
    "| Sunshine      | Amount of bright sunshine                             | hours           | float  |\n",
    "| WindGustDir   | Direction of the strongest gust                       | Compass Points  | object |\n",
    "| WindGustSpeed | Speed of the strongest gust                           | Kilometers/Hour | object |\n",
    "| WindDir9am    | Wind direction averaged of 10 minutes prior to 9am    | Compass Points  | object |\n",
    "| WindDir3pm    | Wind direction averaged of 10 minutes prior to 3pm    | Compass Points  | object |\n",
    "| WindSpeed9am  | Wind speed averaged of 10 minutes prior to 9am        | Kilometers/Hour | float  |\n",
    "| WindSpeed3pm  | Wind speed averaged of 10 minutes prior to 3pm        | Kilometers/Hour | float  |\n",
    "| Humidity9am   | Humidity at 9am                                       | Percent         | float  |\n",
    "| Humidity3pm   | Humidity at 3pm                                       | Percent         | float  |\n",
    "| Pressure9am   | Atmospheric pressure reduced to mean sea level at 9am | Hectopascal     | float  |\n",
    "| Pressure3pm   | Atmospheric pressure reduced to mean sea level at 3pm | Hectopascal     | float  |\n",
    "| Cloud9am      | Fraction of the sky obscured by cloud at 9am          | Eights          | float  |\n",
    "| Cloud3pm      | Fraction of the sky obscured by cloud at 3pm          | Eights          | float  |\n",
    "| Temp9am       | Temperature at 9am                                    | Celsius         | float  |\n",
    "| Temp3pm       | Temperature at 3pm                                    | Celsius         | float  |\n",
    "| RainToday     | If there was rain today                               | Yes/No          | object |\n",
    "| RISK_MM       | Amount of rain tomorrow                               | Millimeters     | float  |\n",
    "| RainTomorrow  | If there is rain tomorrow                             | Yes/No          | float  |\n",
    "\n",
    "Column definitions were gathered from [http://www.bom.gov.au/climate/dwo/IDCJDW0000.shtml](http://www.bom.gov.au/climate/dwo/IDCJDW0000.shtml?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkML0101ENSkillsNetwork20718538-2022-01-01)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Importing the required libraries**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Surpressing warnings:\n",
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import jaccard_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import log_loss\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "import sklearn.metrics as metrics"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the <a href=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-ML0101EN-SkillUp/labs/ML-FinalAssignment/Weather_Data.csv\">Weather Dataset</a>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Weather_Data.csv')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Describing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding the correlation values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "plt.figure(figsize=(20, 20))\n",
    "sns.heatmap(df.corr(), annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transforming Categorical Variables\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we need to convert categorical variables to binary variables. We will use pandas `get_dummies()` method for this.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proc = pd.get_dummies(data=df, columns=['RainToday', 'WindGustDir', 'WindDir9am', 'WindDir3pm'])\n",
    "df_proc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we replace the values of the 'RainTomorrow' column changing them from a categorical column to a binary column. We do not use the `get_dummies` method because we would end up with two columns for 'RainTomorrow' and we do not want, since 'RainTomorrow' is our target.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proc.replace(['No', 'Yes'], [0,1], inplace=True)\n",
    "df_proc[['Date','RainTomorrow']]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Data and Test Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we set our 'features' or x values and our Y or target variable.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proc.drop('Date',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proc = df_proc.astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to predict if the rain will fall or not. So we choose the RainTomorrow column as the target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df_proc.drop(columns='RainTomorrow', axis=1)\n",
    "Y = df_proc['RainTomorrow']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q1) Use the `train_test_split` function to split the `features` and `Y` dataframes with a `test_size` of `0.2` and the `random_state` set to `10`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(features, Y, test_size=0.2, random_state=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q2) Create and train a Linear Regression model called LinearReg using the training data (`x_train`, `y_train`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LinearReg = LinearRegression()\n",
    "LinearReg.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q3) Now use the `predict` method on the testing data (`x_test`) and save it to the array `predictions`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = LinearReg.predict(x_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q4) Using the `predictions` and the `y_test` dataframe calculate the value for each metric using the appropriate function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LinearRegression_MAE = metrics.mean_absolute_error(predictions, y_test)\n",
    "LinearRegression_MSE = metrics.mean_squared_error(predictions, y_test)\n",
    "LinearRegression_R2 = metrics.r2_score(predictions, y_test)\n",
    "print('Linear Regression MAE: ', LinearRegression_MAE)\n",
    "print('Linear Regression MSE: ', LinearRegression_MSE)\n",
    "print('Linear Regression R2: ', LinearRegression_R2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q5) Show the MAE, MSE, and R2 in a tabular format using data frame for the linear model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Report = {'MSE': [LinearRegression_MSE], 'MAE': [LinearRegression_MAE], 'R2': [LinearRegression_R2]}\n",
    "Report=pd.DataFrame(Report)\n",
    "Report.index = ['Linear Regression']\n",
    "Report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q6) Create and train a KNN model called KNN using the training data (`x_train`, `y_train`) with the `n_neighbors` parameter set to `4`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KNN = KNeighborsClassifier(n_neighbors=4)\n",
    "KNN.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q7) Now use the `predict` method on the testing data (`x_test`) and save it to the array `predictions`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = KNN.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q8) Using the `predictions` and the `y_test` dataframe calculate the value for each metric using the appropriate function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KNN_Accuracy_Score = accuracy_score(y_test, predictions)\n",
    "KNN_JaccardIndex = jaccard_score(y_test, predictions, pos_label=0)\n",
    "KNN_F1_Score = f1_score(y_test, predictions, average='weighted')\n",
    "print('KNN Accuracy Score: ', KNN_Accuracy_Score)\n",
    "print('KNN Jaccard Index: ', KNN_JaccardIndex)\n",
    "print('KNN F1 Score: ', KNN_F1_Score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q9) Create and train a Decision Tree model called Tree using the training data (`x_train`, `y_train`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tree = DecisionTreeClassifier(criterion=\"entropy\", max_depth = 8)\n",
    "Tree.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q10) Now use the `predict` method on the testing data (`x_test`) and save it to the array `predictions`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = Tree.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q11) Using the `predictions` and the `y_test` dataframe calculate the value for each metric using the appropriate function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tree_Accuracy_Score = accuracy_score(y_test, predictions)\n",
    "Tree_JaccardIndex = jaccard_score(y_test, predictions, pos_label=0)\n",
    "Tree_F1_Score = f1_score(y_test, predictions)\n",
    "print('Tree Accuracy Score: ', Tree_Accuracy_Score)\n",
    "print('Tree Jaccard Index: ', Tree_JaccardIndex)\n",
    "print('Tree F1 Score: ', Tree_F1_Score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q12) Use the `train_test_split` function to split the `features` and `Y` dataframes with a `test_size` of `0.2` and the `random_state` set to `1`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(features, Y, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q13) Create and train a LogisticRegression model called LR using the training data (`x_train`, `y_train`) with the `solver` parameter set to `liblinear`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = LogisticRegression(solver='liblinear')\n",
    "LR.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q14) Now, use the `predict` method on the testing data (`x_test`) and save it to the array `predictions`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = LR.predict(x_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q15) Using the `predictions` and the `y_test` dataframe calculate the value for each metric using the appropriate function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR_Accuracy_Score = accuracy_score(y_test, predictions)\n",
    "LR_JaccardIndex = jaccard_score(y_test, predictions, pos_label=0)\n",
    "LR_F1_Score = f1_score(y_test, predictions)\n",
    "LR_Log_Loss = log_loss(y_test, LR.predict_proba(x_test))\n",
    "print('LR Accuracy Score: ', LR_Accuracy_Score)\n",
    "print('LR Jaccard Index: ', LR_JaccardIndex)\n",
    "print('LR F1 Score: ', LR_F1_Score)\n",
    "print('LR Log Loss: ', LR_Log_Loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q16) Create and train a SVM model called SVM using the training data (`x_train`, `y_train`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVM = svm.SVC(kernel='linear')\n",
    "SVM.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q17) Now use the `predict` method on the testing data (`x_test`) and save it to the array `predictions`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = SVM.predict(x_test)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### Q18)Using the `predictions` and the `y_test` dataframe calculating the value for each metric using the appropriate function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVM_Accuracy_Score = accuracy_score(y_test, predictions)\n",
    "SVM_JaccardIndex = jaccard_score(y_test, predictions, pos_label=0)\n",
    "SVM_F1_Score = f1_score(y_test, predictions)\n",
    "print('SVM Accuracy Score: ', SVM_Accuracy_Score)\n",
    "print('SVM Jaccard Index: ', SVM_JaccardIndex)\n",
    "print('SVM F1 Score: ', SVM_F1_Score)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Report\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Showing the Accuracy,Jaccard Index, F1-Score and LogLoss in a tabular format using data frame for all of the above models.\n",
    "\n",
    "\\*LogLoss is only for Logistic Regression Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Report = {'Classification Algorithm': ['KNN, K=4', 'Decision Tree',  'LogisticRegression','SVM'],\n",
    "          'Accuracy Score': [KNN_Accuracy_Score, Tree_Accuracy_Score, LR_Accuracy_Score, SVM_Accuracy_Score],\n",
    "          'Jaccard Score': [KNN_JaccardIndex, Tree_JaccardIndex, LR_JaccardIndex, SVM_JaccardIndex,],\n",
    "          'F1-score': [KNN_F1_Score, Tree_F1_Score, LR_F1_Score, SVM_F1_Score], \n",
    "          'LogLoss': ['N/A', 'N/A', LR_Log_Loss, 'N/A']}\n",
    "Report = pd.DataFrame(Report)\n",
    "Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "fig = make_subplots(rows=1, cols=1)\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Bar(x=Report['Classification Algorithm'], y=Report['Accuracy Score'], name='Accuracy Score'),\n",
    "    row=1, col=1\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Bar(x=Report['Classification Algorithm'], y=Report['Jaccard Score'], name='Jaccard Score'),\n",
    "    row=1, col=1\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Bar(x=Report['Classification Algorithm'], y=Report['F1-score'], name='F1-score'), row=1,col=1\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Bar(x=Report['Classification Algorithm'], y=Report['LogLoss'], name='LogLoss'), row=1,col=1\n",
    ")\n",
    "\n",
    "fig.update_layout(title_text=\"Accuracy Scores Of Classification Algorithms\")\n",
    "fig.update_yaxes(title_text=\"Score\", row=1, col=1)\n",
    "fig.update_xaxes(title_text=\"Classification Algorithm\", row=1, col=1)\n",
    "fig.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Observation\n",
    "* We can see that KNN with K=4 is the best model for predicting rain with almost 80% accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
